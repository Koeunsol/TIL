2019-10-1
재명T_ 회귀분석 고급 + 클러스터링

@최근접 이웃
    -예측하고자 하는 사례와 가장 비슷한 사례를 k개 찾아 동일하게 예측
    -e.x) 감정평가, 가격
    -유사도를 수치화해서 나타낼 수 있어야 함
    -절대적인 기준이 없어서 애매하지만, 유사도가 영향을 많이 끼침
    -단점: 데이터가 많으면 찾는 시간이 오래 걸림

@의사결정나무
    -스무고개와 같이 Y/N 질문을 반복하여 예측
    -질문의 수가 적으면 해석하기가 쉬움
    -단점: 데이터가 조금만 달라져도 결과가 크게 달라질 수 있음

@앙상블
    -하나의 모형으로 예측을 잘 하는데 한계가 있음
    -앙상블: 여러 개의 모형을 만들어 평균/다수결로 예측하는 방법
    -최근 머신러닝은 그래디언트부스팅, 딥러닝 등 앙상블이 주도

@클러스터링
    -비슷한 사례들끼리 군집으로 모으는 것
    -대부분 군집의 수는 하이퍼파라미터로 정해주어야 함

	활용
    -비슷한 패턴끼리 묶어 특정 집단에 맞춘 카드 마케팅

	클러스터링의 종류
    -범주를 정확히 정할 수는 없지만, 각각의 기준에 따라 종류가 나뉘어짐
    -상황에 따라 적절하게 기법을 이용하는 것이 좋겠다…
    -어떤 방법을 쓰냐에 따라서 클러스터링이 달라짐

        종류1: k-Means
            -k(k는 통계에서 보통 개수를 의미함)-Means(평균): K 개의 평균
            -가장 널리 사용되는 클러스터링 방법
                e.x) 고객을 k개의 유형으로 분류하고, 어떤 유형의 집단인지 알 수있음
            -같은 집단끼리는 모여있음
            -작동 방식: 평균을 먼저 찍고 … k개의 기준으로 분류함… 또 기준으로 평균을 내고 그것이 기준이 되고 반복…. 안될때까지 함
            -계산 속도가 매우 빠름
            -KNN과는 아무 상관없음…. 


            k-Means의 특징
            -k만 정해주면 되므로 간단
            -거리를 정할 수 있고, 중심점 주변에 사례들이 모여있는 경우에 사용할 수 있음
                - 단점: 중심점 주변에 사례들이 모여있지 않을수있음…
            -소수의 사례만 무작위로 뽑아 클러스터링 할수도 있음(미니배치 k-means)
                - 미니배치 : 속도를 빠르게 하는 방법


        종류2: Affininty Propagation
            -중심점 대신 대표(exemplar)를 찾는 방법
            -exemplar의 용법
                 e.x) 새의 exemplar는 참새
            -responsibility와 availability라는 수치를 반복적으로 계산
            -의미있는 수치를 만듦
            -k-Means와 달리 클러스터의 개수를 미리 정하지 않음


		종류3: Mean Shift
            -점 주변으로 특정 거리 내에 있는 점들의 평균을 구해 새로운 중심점을 만듦 -> 반복
            -이런게 있구나.. 써먹긴 어렵지만 … 잘난척할 때 쓰자..
	
		종류4: Spectral Clustering
            -비슷한 사례들끼리 그래프(점과 점을 선으로 이은)를 만듦
            -장점: K-Means와 달리 덜 뭉쳐져 있어도 잘 작동함
                e.x)관계를 맺는 SNS를 다룰 때 잘 활용이 가능
            -데이터가 많으면 잘 안돌아가서 잘 안씀
            -아이디어 는 좋다

		종류5: 위계적 클러스터링
            -위의 방법들은 한번에 모두 클러스터를 함
                -위계적 클러스터링: 순차적으로 합쳐나가는 과정을 반복
            -장점: 나중에 클러스터를 정해줄 수 있음
            -제일 오래된 방법이라 요샌.. 많이 안씀

		종류6: DBSCAN 
            -많이 쓰임
            -이론상 최고 좋지만 … 입실론과 어쩌구를 설정하지 못한다는 단점이?잇다
            -Mean Shift와 비슷함
                -차이: 비슷한 관계를 이어가는 방식
                -인싸들끼리만 묶어줌… 관계맺고 있지 못한 아싸는 안끼워줌 ㅠㅠ
                -장단점: 멀리 떨어진, 관계맺지 못한 아싸는 아예 배제함 
            -거리와 기준을 정하고, 그 안에서 관계가 이어진 것들만을 묶어줌
            -장점: K-means와 달리 관계를 따라가는 방식이라 뭉쳐진 상태가 아니어도 괜찮음
                + 대용량 데이터도 잘돌아감

		종류7: OPTICS
            -DBSCAN 에서 지정해줄 것이 거리와 기준이었다면
            -이것은 기준만 정해주면 됩니다

		종류8: BIRCH
            -대용량 데이터를 빠르게 클러스터링하기 위한 알고리즘
        
        @최소 K-Means, DBSCAN, Agglomerative Clustering 알아두자...

    ~분류와 클러스터링의 차이~
    -클러스터링에서는 범주가 잠재변수
    -범주를 정확히 알 수 없음 = 정답이 없음
    -기준이 주관적이므로 내가 잘못했어도 알수 없음…

@클러스터링 평가
    1)사례들이 군집의 중심에서 얼마나 가까운가?
        -낮을수록 좋음
        -0이 최선
        -빠글빠글 모여있는 정도


    2)다른 군집과 얼마나 다른가?
        -높을수록 좋음

@클러스터링 평가 지표의 문제점
    -정답이 없어서 마땅한 지표가 없다
    -클러스터링의 결과를 바탕으로 행동을 취했을 때 그 성과로 판단
